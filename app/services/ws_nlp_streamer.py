from typing import AsyncIterator, Optional
import asyncio
import torch
from app.services.vis_nlp import generate_caption
from app.services.vis_nlp import VISNLPEXTRACTOR, CaptionGenerator, load_Generator
from transformers import AutoTokenizer


class WsNLPStreamer:
    """
    WebSocket ì „ìš© NLP ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤
    - Vision + NLP ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ìº¡ì…˜ ìƒì„± ìŠ¤íŠ¸ë¦¬ë°.
    - ì´ë¯¸ í…ì„œ í˜•íƒœì˜ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ ì²˜ë¦¬.
    """
    
    # í´ë˜ìŠ¤ ë³€ìˆ˜ë¡œ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ì €ì¥ (ì‹±ê¸€í†¤ íŒ¨í„´)
    _nlp_model = None

    def __init__(self):
        pass

    @classmethod
    def get_nlp_model(cls):
        """ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‹±ê¸€í†¤ìœ¼ë¡œ ê´€ë¦¬"""
        if cls._nlp_model is None:
            print("NLP ëª¨ë¸ ë¡œë”© ì‹œì‘...")
            try:
                # ëª¨ë¸ êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”
                visnlp_extractor = VISNLPEXTRACTOR(
                    img_dim_h=512, img_dim_w=512, patch_size=16, 
                    embed_dim=256, num_heads=4, depth=4
                )
                
                # í† í¬ë‚˜ì´ì € ë¡œë“œ (BERT ê¸°ë°˜)
                tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')
                
                # ìº¡ì…˜ ìƒì„±ê¸° ì´ˆê¸°í™”
                caption_generator = CaptionGenerator(
                    visnlp_extractor=visnlp_extractor,
                    vocab_size=tokenizer.vocab_size,
                    embed_dim=256,
                    num_heads=4,
                    ff_dim=2048,
                    num_layers=4
                )
                
                # ëª¨ë¸ ë¡œë“œ
                model = load_Generator(caption_generator, 'app/models/image_meta.pth')
                
                # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ í•¨ê»˜ ì €ì¥
                cls._nlp_model = {
                    'model': model,
                    'tokenizer': tokenizer
                }
                
                print("NLP ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            except Exception as e:
                print(f"NLP ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                raise e
        return cls._nlp_model
    
    @classmethod
    def preload_model(cls):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ëª¨ë¸ì„ ë¯¸ë¦¬ ë¡œë“œ"""
        if cls._nlp_model is None:
            print("ğŸš€ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ NLP ëª¨ë¸ ì‚¬ì „ ë¡œë”©...")
            cls.get_nlp_model()
            print("âœ… NLP ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì™„ë£Œ!")

    @classmethod
    async def stream_caption_generation(cls, image_tensor: torch.Tensor, meta_prompt: str) -> AsyncIterator[str]:
        """
        ì´ë¯¸ì§€ í…ì„œì™€ ë©”íƒ€ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ìº¡ì…˜ì„ ìƒì„±í•˜ê³  ìŠ¤íŠ¸ë¦¬ë°
        generate_captionì„ ëŒ€ì²´í•˜ëŠ” í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° ë²„ì „
        """
        try:
            # ì‹±ê¸€í†¤ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© (ë¯¸ë¦¬ ë¡œë“œëœ ëª¨ë¸ ì¦‰ì‹œ ì‚¬ìš©)
            nlp_model = cls.get_nlp_model()
            
            # ì‹¤ì‹œê°„ í† í° ìŠ¤íŠ¸ë¦¬ë° (generate_captionì„ ëŒ€ì²´)
            async for token in cls._generate_caption_stream(nlp_model, image_tensor, meta_prompt, max_len=48, device='cpu'):
                yield token
                    
        except Exception as e:
            yield f"ìº¡ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    @classmethod
    async def _generate_caption_stream(cls, model_dict, image, meta, max_len=48, device='cpu'):
        """
        ì‹¤ì‹œê°„ìœ¼ë¡œ í† í°ì„ ìƒì„±í•˜ë©´ì„œ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ë‚´ë¶€ ë©”ì„œë“œ
        vis_nlp.pyì˜ generate_caption í•¨ìˆ˜ë¥¼ ì§„ì§œ í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° ë²„ì „ìœ¼ë¡œ êµ¬í˜„
        """
        import asyncio
        
        model = model_dict['model']
        tokenizer = model_dict['tokenizer']
        
        model.eval()
        image = image.to(device)       
        meta = [meta]                                 

        with torch.no_grad():
            # 1. ì´ë¯¸ì§€ì™€ ë©”íƒ€ë°ì´í„°ì—ì„œ ë©”ëª¨ë¦¬ ì¶”ì¶œ
            memory = model.extractor(image, meta).to(device)    
            
            # 2. ì‹œì‘ í† í°ìœ¼ë¡œ ì´ˆê¸°í™”
            input_ids = torch.tensor([[tokenizer.cls_token_id]], device=device) 
            
            # 3. í† í°ë³„ë¡œ ì‹¤ì‹œê°„ ìƒì„± ë° ìŠ¤íŠ¸ë¦¬ë°
            for step in range(max_len - 1):
                # ë‹¤ìŒ í† í° ì˜ˆì¸¡
                logits = model.decoder(input_ids, memory) 
                next_token_logits = logits[:, -1, :]      
                next_token = torch.argmax(next_token_logits, dim=-1)
                
                # í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                token_text = tokenizer.decode(next_token, skip_special_tokens=True)
                
                # íŠ¹ìˆ˜ í† í°ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ìŠ¤íŠ¸ë¦¬ë°
                if (next_token.item() not in [tokenizer.cls_token_id, tokenizer.sep_token_id, tokenizer.pad_token_id] 
                    and token_text.strip()):  # ë¹ˆ í† í°ë„ ì œì™¸
                    yield token_text + " "
                
                # ë‹¤ìŒ ë°˜ë³µì„ ìœ„í•´ input_ids ì—…ë°ì´íŠ¸
                input_ids = torch.cat([input_ids, next_token.unsqueeze(1)], dim=1)

                # ì¢…ë£Œ í† í°ì´ë©´ ì¤‘ë‹¨
                if next_token.item() == tokenizer.sep_token_id:
                    break
                    
                # ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ë‹¤ë¥¸ ì‘ì—…ì´ ì‹¤í–‰ë  ìˆ˜ ìˆë„ë¡ í•¨
                await asyncio.sleep(0.01)

    async def process_tensor_and_meta(self, image_tensor: torch.Tensor, meta_prompt: str) -> AsyncIterator[str]:
        """
        ì´ë¯¸ì§€ í…ì„œì™€ ë©”íƒ€ í”„ë¡¬í”„íŠ¸ë¥¼ ì²˜ë¦¬í•˜ì—¬ ìº¡ì…˜ ìƒì„±
        """
        try:
            yield "í…ì„œ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n"
            
            # ìº¡ì…˜ ìƒì„± ìŠ¤íŠ¸ë¦¬ë°
            async for chunk in self.stream_caption_generation(image_tensor, meta_prompt):
                yield chunk
                
        except Exception as e:
            yield f"í…ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
